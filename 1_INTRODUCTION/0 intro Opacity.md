


**Epistemic opacity is a context-dependent feature of computational science**
“Here a process is epistemically opaque relative to a cognitive agent X at time t just in case X does not know at t all of the epistemically relevant elements of the process.” (Humphreys, 2009, p. 618)

A cognitive agent is not able to know and understand all epistemically relevant elements of a computational process.


**Functional opacity due to genetic programming**
“A program generated by machine learning may fail to be functionally transparent if its algorithm was developed autonomously, without being programmed by a person, as in genetic programming.” (Creel, 2020, p. 10) 


**Structural opacity is not correlated with functional opacity similar to how acc. to Sullivan knowledge of model implementation is irrelevant for understanding phenomena from the model**
“It is possible to know the algorithm that the code realizes but not know how the code realizes it, i.e. to have functional but not structural transparency.” (Creel, 2020, p. 13)


**Computational opacity of algorithms that involve emergent properties, complexity effects etc. like in DNN is not easily resolved by process decomposition**

“The difficulty in determining which emergent properties, complexity effects, or unexpected errors the code might possess cannot always be resolved by being able to trace the code line-by-line or function-by-function. Only at a higher level does structural opacity emerge.” (Creel, 2020, p. 15)

Higher-level emergent properties are not decomposable (see Humphrey, 2004)

“Thus, a second source of opacity would remain even if hand checking were possible: the program would still not be fully transparent because we could not understand how all the steps interact to bring about the algorithm or to what extent each individual step contributed to the final result.” (Creel, 2020, p. 15)


**The degree of structural opacity is a function of model complexity**
“The structural opacity of a large cosmology or climate simulation is an accidental function of size and accretion; a similar but smaller program would be easier to understand.” (Creel, 2020, p. 19) 


**Functional opacity of DNN due to complexity**
“However, it is just not the case that we know f in the same way we know the factorial function.” (Räz and Beisbart, 2022, p. 7)

“Second, even if we granted that ̂ f were implemented by a DNN, ̂ f is not known in the way in which the factorial is known because ̂ f is extremely complex.” (Räz and Beisbart, 2022, p. 7)

The true and learned classifier function cannot be described like the true factorial function because of complexity. It is practically impossible to know the true classifier function.

