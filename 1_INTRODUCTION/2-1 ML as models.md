idealization, simulation, abstraction, similarity:
- “The semantic conception provides a straightforward answer to the question of how models give us knowledge of the world: they specify structures that are posited as possible representations of either the observable phenomena or, even more ambitiously, the underlying structures of the real target systems.” (Knuuttila and Merz, 2009, p. 4) ==semantic approach to modelling==
- “Thus, according to the semantic view, the structure specified by a model represents its target system if it is either structurally isomorphic or somehow similar to it.” (Knuuttila and Merz, 2009, p. 4)

**Three distinct senses of DNN as "models" identified by Boge**
“In sum, at least three distinct senses of ‘model’ should be distinguished here, which, so far as I can see, exhaust the use of ‘model’ in the DL literature: (a) DNNs as (crude) models of actual brains, (b) the algorithms employed in DL as abstract, selective models of human learning, and (c) the input–output mappings approximated through training as models of features pertaining to the data, such as their statistical distribution.” (Boge, 2022, p. 46)

**DNN as models or techniques? DNN as crude models of the brain**
“Napoletani et al. (2011, p. 13) actually refrain from calling DNNs ‘models’ altogether and solely use ‘technique’. Humphreys (2013,  p. 580), on the other hand, acknowledges the possibility of “simulating neural dynamics” with DNNs, but also urges to “keep separate uses of neural nets as simulation models from their use as techniques in computational science”, and additionally finds most neural nets to be “extremely crude models of real brains[...].” The latter verdict is frequent in the literature (e.g. Chirimuuta, 2020; Goodfellow et  al., 2016; Sullivan, 2019), not least ==because feed-forward processing and gradient descent are biologically implausible==;” (Boge, 2022, p. 45)

**Algorithms employed in DNN as abstract models for human learning**
“Note that the learning algorithm involved in deriving this model may itself count as yet another model: Buckner (2018) points to the possibility of understanding concept abstraction on the basis of deep convolutional nets, without drawing too close a parallel to either brain processes or most details of human cognition. Similarly, it may be possible to understand certain errors made by DNNs in analogy to errors made by humans under similar conditions (Buckner, 2021, for discussion).” (Boge, 2022, p. 46) 

**Objectual approach by Knuuttila and Merz**
Knuuttila and Merz (2009) presents an objectual approach to modelling according to which a model is an 'concrete constructed object'. Its function is not representive, but productive. The way a model provides understanding depends on the way we interact with it and how it is implemented. Thus, a single model may provide a multiplicity of understanding depending on its practical use. The specific implementation of a model is key to understand how the model affords understanding. The objectual approach allows for models to be highly unrealistic while still allowing for understanding to be gained. 


A classical approach to scientific modelling is that relevant model features are measurable and specified, parameter values remain largely consistent across domains of application and model assumptions are few. On the other hand, the idea of DNN models is that their relevant model features are initially unspecified and are acquired through training. However, due to their high level of opacity, it proves to be difficult to determine which features a DNN model tracks and what the parameter values are. When DNN models are applied to new domains, their parameterization usually changes drastically (Scorzato_2024).