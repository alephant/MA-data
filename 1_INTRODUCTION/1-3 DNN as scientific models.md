Accounts of scientific understanding
What are the crucial conditions for understanding from a model?
The history and practice of science regularly shows that its theories and models are not true descriptions of reality. If we assume that we still understand something with (mostly) untrue models - what characteristics of a model enable us to do so, and of what kind of understanding do we mean?
- idealized, fictional models are untrue
- 
De Regt: 
when you understand, you do not gain some type of knowledge, but rather you gain the skill to predict behavior of the target system.
understanding enables us to predict
intelligbility: what values do scientist attribute to the theoretical virtues of a model


If we embrace scientific understanding as something that models enable us to gain and reject the idea understanding has no place in science (e.g. on anti-realist accounts of explanation like Hempel's covering law model, 1965), then we need to answer the question what this kind of understanding is.
Scientific realism argues that understanding can only be gained from theories and models that are true. i.e. to understand the world requires to have an at least approximately realistic representation of the world. However, higher realism of a model makes it typically less intelligible.






Model:
Knuuttila and Merz (2009) presents an objectual approach to modelling according to which a model is an 'concrete constructed object'. Its function is not representive, but productive. The way a model provides understanding depends on the way we interact with it and how it is implemented. Thus, a single model may provide a multiplicity of understanding depending on its practical use. The specific implementation of a model is key to understand how the model affords understanding. The objectual approach allows for models to be highly unrealistic while still allowing for understanding to be gained. 

how-possibly explanations/ heuristics etc. do enable understanding:
- “Lipton (2009, pp. 49–52) presents interesting arguments for the thesis that potential (how-possibly) explanations can provide understanding” (Regt, 2015, p. 3789)

highly idealized and abstract models that enable understanding 


model
target phenomenon
model-induced explanation
complex model


idealization
simulation
abstraction
similarity:
- “The semantic conception provides a straightforward answer to the question of how models give us knowledge of the world: they specify structures that are posited as possible representations of either the observable phenomena or, even more ambitiously, the underlying structures of the real target systems.” (Knuuttila and Merz, 2009, p. 4) ==semantic approach to modelling==
- “Thus, according to the semantic view, the structure specified by a model represents its target system if it is either structurally isomorphic or somehow similar to it.” (Knuuttila and Merz, 2009, p. 4)


explainability
intelligibility: as pragmatic value
contextuality: purpose-context, 
transparency
relation between prediction and understanding

biological inspiration as an argument for ML models
implementation
parameterization







what are generally accepted criteria that models need to enable understanding?
what are epistemic criteria? what are non-epistemic criteria to evaluate whether a model is accepted for scientific purposes or not?