Accounts of scientific understanding
What are the crucial conditions for understanding from a model?
The history and practice of science regularly shows that its theories and models are not true descriptions of reality. If we assume that we still understand something with (mostly) untrue models - what characteristics of a model enable us to do so, and of what kind of understanding do we mean?
- idealized, fictional models are untrue




If we want to understand how DNN can be used as scientific models, we first need to consider which properties models much have to provide understanding and how these criteria relate to DNN.

Models are intelligible in virtue of modellers that can understand and use them to gain understanding of phenomena in the world. In this sense, intelligibility is a context-dependent property of a model as it relates to the ability of the modeller or other scientists' to use the model to make inferences on the target phenomenon. An intelligible model doesn't need to be realistic to provide understanding (DeRegt_2005, 2015). 





Model:
Knuuttila and Merz (2009) presents an objectual approach to modelling according to which a model is an 'concrete constructed object'. Its function is not representive, but productive. The way a model provides understanding depends on the way we interact with it and how it is implemented. Thus, a single model may provide a multiplicity of understanding depending on its practical use. The specific implementation of a model is key to understand how the model affords understanding. The objectual approach allows for models to be highly unrealistic while still allowing for understanding to be gained. 

how-possibly explanations/ heuristics etc. do enable understanding:
- “Lipton (2009, pp. 49–52) presents interesting arguments for the thesis that potential (how-possibly) explanations can provide understanding” (Regt, 2015, p. 3789)

highly idealized and abstract models that enable understanding 


model
target phenomenon
model-induced explanation
complex model


idealization
simulation
abstraction
similarity:
- “The semantic conception provides a straightforward answer to the question of how models give us knowledge of the world: they specify structures that are posited as possible representations of either the observable phenomena or, even more ambitiously, the underlying structures of the real target systems.” (Knuuttila and Merz, 2009, p. 4) ==semantic approach to modelling==
- “Thus, according to the semantic view, the structure specified by a model represents its target system if it is either structurally isomorphic or somehow similar to it.” (Knuuttila and Merz, 2009, p. 4)


explainability
intelligibility: as pragmatic value
contextuality: purpose-context, 
transparency
relation between prediction and understanding

biological inspiration as an argument for ML models
implementation
parameterization







what are generally accepted criteria that models need to enable understanding?
what are epistemic criteria? what are non-epistemic criteria to evaluate whether a model is accepted for scientific purposes or not?