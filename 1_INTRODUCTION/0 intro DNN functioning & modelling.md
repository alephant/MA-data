**DNN use is driven by the assumption that true function f is in the set of all functions f representable**
“Deep learning is a machine learning technique based on artificial neural networks that is widely used for prediction and classification tasks. The goal of deep learning is to automate the search for a function ˆ f that approximates the true function f that generates observed data. The fundamental assumption that motivates the use of deep learning is that f is in the set of functions F representable by a neural network given some particular architecture and (hyper)parameterization. Of course, for any given parameterization k, we have no way of knowing a priori whether f is element of Fk. However, deep neural networks are universal approximators (Hornik et al. 1989), so the assumption is at least principled.” (Duede, 2023, p. 1091)




**Supervised and unsupervised ML training**
“There are two main classes of ML systems: “supervised” and “unsupervised.” Generally speaking, supervised ML systems assist with prediction—involving, in the simplest case, a mapping from some known input x to an unknown output y. This mapping is made possible through training, which in turn takes place on a set of pre-labeled input-output pairs (xi , yi). If we wanted to train a system to recognise the image of a dog or cat, for example, we might conceive of xi as a feature vector (consisting of all the notable features of the object in question, e.g. ear, tail, fur, nose, etc.), and conceive of yi as the set of class designations corresponding to those features (we can specify that y takes one value in {1, ..., C}, where C stands for the number of classes; here C = 2, i.e. DOG or CAT). In this example, “supervision” would consist of a human labeler “telling” the system which features pertain to a dog and which to a cat. If D = {(xi , yi)}, where D is the training set, then we can say that as the size of D grows, the more “experience” the system acquires and the more accurate the system will be in its predictions when used on unseen data. The difference with unsupervised learning is that there is no similar process of labeling—no output data yi used in training—so D = {xi}. (Unsupervised learning is thus concerned less with prediction than with description, or the discovery of patterns in datasets.)” (Zerilli, 2022, p. 6)

