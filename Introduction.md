1. ML models as scientific models
	1. General motivation of my thesis
		1. examples on the predictive strength of DNN, where DNN are already used as models
	2. Criteria for understanding from models and theories
		1. Account of scientific understanding: theories need to be intelligible to enable (explanatory) understanding - so what about opaque ML models? (de Regt, 2017)
		2. explanatory understanding has to get close to correct understanding - can ML model get us close to correct understanding? (Khalifa, 2017)
	4. DNN structure and modelling
		1. Structural description
		2. DNN modelling: training, validating, testing
		3. DNN implementation & parameterization
	5. Distinction between und. model implementation vs. understanding from models
	6. thus, DNN with questionable potential for understanding?
		1. general: DNN opacity, complexity, less modeler control
		2. contrasting prediction and explanation/ understanding (stress my thesis is about understanding and not explanation)
		3. helpful sources: Cichy on arguments pro and contra DNN in cognitive science
2. the black box problem of DNN
3. 

