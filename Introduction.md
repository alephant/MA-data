1. ML models as scientific models
	1. DNN as predictive powerhouses
	2. DNN as scientific models
		1. Reflecting key aspects of scientific modelling on the background of ML models
			1. what are models: surrogates, Weisberg
			2. how do they model / represent / mapping relation: isomorphism, similarity, teleological
		2. lack of transparency = lack of explanation and understanding?
		3. First, what are commonly discussed criteria for models to enable scientific explanation and understanding?
			1. Prediction versus or indicative of explanation/understanding?
				1. my thesis is about understanding and not explanation
			2. The nature of good scientific models (Cichy and Kaiser)
			3. Account of scientific understanding: theories need to be intelligible to enable (explanatory) understanding - so what about opaque ML models? (de Regt, 2017)
			4. explanatory understanding has to get close to correct understanding - can ML model get us close to correct understanding? (Khalifa, 2017)
		4. Second, are these criteria met by ML models? What are views on criteria for ML models to count as scientific models? Three key distinctions to make:
			1. ML models as scientific models: model-centric vs. model-external view
			2. what to understand: understanding of vs understanding with ML models:
				1. how is understanding model implementation and understanding phenomena from models related?
			3. understanding from ML models: outlook on narrow and wide view
	4. DNN structure and modelling
		1. Structural description
		2. DNN modelling: training, validating, testing
		3. DNN implementation & parameterization
		4. thus, DNN with questionable potential for understanding?
2. the black box problem of DNN
3. 

