1. ML models as scientific models
	1. Criteria for understanding from models and theories
		1. Account of scientific understanding: theories need to be intelligible to enable (explanatory) understanding - so what about opaque ML models? (de Regt, 2017)
		2. explanatory understanding has to get close to correct understanding - can ML model get us close to correct understanding? (Khalifa, 2017)
	2. understanding model implementation vs. understanding from models
	3. thus, DNN as predictive powerhouses with questionable potential for understanding?
		1. general: DNN opacity, complexity, less modeler control
		2. contrasting prediction and explanation/ understanding (stress my thesis is about understanding and not explanation)
		4. helpful sources: Cichy on arguments pro and contra DNN in cognitive science
2. the black box problem of DNN
	1. DNN structure
	2. DNN modelling
		1. Sullivan's level of DNN black boxes: high-level functioning vs. low-level implementation
		2. 


DNN are predictive powerhouses.