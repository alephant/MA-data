What is the overall argument that Sullivan is making?
Sullivan rejects the popular claim that the opacity and complexity of DNN models are an in-principle problem for gaining understanding from DNN models. In contrary, she argues that it is not the opacity and complexity of DNN models that are the limiting factor when considering DNN as explanatory models, but like with any other model, simple or complex, it comes down to whether the model is linked to the target phenomenon. She introduces the notion of link uncertainty as the actual limiting factor.

What is link uncertainty?
At best, by using a model we want to understand what the actual causes of a phenomenon are. To enable the understanding of actual causes, the causes that the model identified must be empirically validated as actual causes. As long as the causes identified by the model are not empirically shown to be the actual causes, there is a high degree of link uncertainty between the model and the target phenomenon.

For which models is link uncertainty important?
It is important to remove link uncertainty for any kind of model. Sullivan writes “This general claim about the importance of removing link uncertainty in order to gain understanding stretches beyond the cases of minimal and complex models.” (Sullivan, 2022, p. 27)

How can link uncertainty be removed?
The question of how to remove link uncertainty is the question of how to establish a link between model and target. 

What of the algorithms executed by computational systems such as DNN must be known?
Sullivan differentiates between the goal of an algorithm and how the algorithm achieves its goal.
How the algorithm of DNN achieves its goal can be opaque (implementation opacity).
“However, the general goal of the algorithm must be known for understanding to be possible.”
The goals of lower-level algorithms become a matter of implementing higher-level algorithms. Thus, goals of lower-level algorithms become a matter of how a trained DNN achieve its specific classification or prediction goal. 
It seems that Sullivan adheres to the notion that a trained DNN executes a "highest-level" algorithm that is identical to what the DNN is designed to achieve. For her, this algorithm is known. 



